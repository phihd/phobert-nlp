{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "introductory-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True to skip training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "black-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import functools\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d06f24",
   "metadata": {},
   "source": [
    "Material:  \n",
    "https://www.vinai.io/phobert-the-first-public-large-scale-language-models-for-vietnamese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-wrist",
   "metadata": {},
   "source": [
    "# 1. Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-commission",
   "metadata": {},
   "source": [
    "https://github.com/datquocnguyen/VnDT#data-split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-berry",
   "metadata": {},
   "source": [
    "https://github.com/datquocnguyen/VnDT/blob/master/VnDT-paper-CameraReadyVersion.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-manner",
   "metadata": {},
   "source": [
    "## 1.1 Read the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "temporal-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_1(file_name):\n",
    "    with open(file_name, encoding='utf8') as f:\n",
    "        # line = ['Np Proper noun','Nc Classifier noun',...]\n",
    "        lines = re.split('\\n',f.read())\n",
    "    \n",
    "    tags = []\n",
    "    tag_dict = {}\n",
    "    for line in lines:\n",
    "        tmp = line.split(' ',1)\n",
    "        tags.append(tmp[0])\n",
    "        tag_dict[tmp[0]] = tmp[1]\n",
    "        \n",
    "    return tags, tag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-sugar",
   "metadata": {},
   "source": [
    "## 1.2 Read train - dev - test corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "violent-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_2(file_name):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name - string\n",
    "        a path to a file with an annotated corpus\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    words - a list of lists of words\n",
    "    tags - a list of lists of tags\n",
    "        For example, the first sentence in a file is word1-tag1, word2-tag2 \n",
    "        and the next sentence is word3_/_tag3. Then you should get:\n",
    "        words = [['word1','word2'],['word3']]\n",
    "        tags = [['tag1','tag2'],['tag3']]\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_name, sep='\\t|\\n', names = ['idx','word','c3','c4','tag','c6','c7','c8','c9','c10'])\n",
    "    \n",
    "    words = []\n",
    "    tags = []\n",
    "    sentence_words = []\n",
    "    sentence_tags = []\n",
    "    prev_idx = 0\n",
    "    for _,row in df.iterrows():\n",
    "        if row['idx'] != prev_idx+1:\n",
    "            words.append(sentence_words)\n",
    "            tags.append(sentence_tags)\n",
    "            sentence_words = []\n",
    "            sentence_tags = []\n",
    "            \n",
    "        sentence_words.append(row['word'])\n",
    "        sentence_tags.append(row['tag'])\n",
    "        prev_idx = row['idx']\n",
    "            \n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-haiti",
   "metadata": {},
   "source": [
    "## 1.3 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fa0f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/m/home/home1/12/dangp1/unix/POS_NER'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "streaming-credits",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/12/dangp1/unix/.conda/envs/concac/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8976\n",
      "199\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "tags_vocab_path = cwd+'/data/tags_vocab.txt'\n",
    "train_path = cwd+'/data/train.txt'\n",
    "valid_path = cwd+'/data/dev.txt'\n",
    "test_path = cwd+'/data/test.txt'\n",
    "\n",
    "tags_vocab, tags_vocab_dict = read_1(tags_vocab_path)\n",
    "train_words, train_tags = read_2(train_path)\n",
    "valid_words, valid_tags = read_2(valid_path)\n",
    "test_words, test_tags = read_2(test_path)\n",
    "\n",
    "print(len(train_words))\n",
    "print(len(valid_words))\n",
    "print(len(test_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-recycling",
   "metadata": {},
   "source": [
    "## 1.4 Enumerate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "municipal-jaguar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tag2num(tags_vocab):\n",
    "    return dict(zip( tags_vocab, range(1, len(tags_vocab)+1) ))\n",
    "\n",
    "tag2num = tag2num(tags_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "median-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enumerate_tags(sentence_tags, tag2num):\n",
    "    converted_tags = [ list(map(lambda x: tag2num[x], sentence_tag)) for sentence_tag in sentence_tags ]\n",
    "    return converted_tags\n",
    "\n",
    "enumerated_train_tags = Enumerate_tags(train_tags, tag2num)\n",
    "enumerated_valid_tags = Enumerate_tags(valid_tags, tag2num)\n",
    "enumerated_test_tags = Enumerate_tags(test_tags, tag2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "african-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-capacity",
   "metadata": {},
   "source": [
    "# 2. Study the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-recruitment",
   "metadata": {},
   "source": [
    "# 3. Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ahead-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encode(Dataset):\n",
    "    def __init__(self, words, tags, tags_vocab, tokenizer, max_len, pad_idx):\n",
    "        self.data = words\n",
    "        self.labels = tags\n",
    "        self.tags_vocab = tags_vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        self.len = len(self.data)\n",
    "        self.max_len = max_len\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.data[index],\n",
    "            None,\n",
    "            add_special_tokens=False,\n",
    "            max_length=self.max_len,\n",
    "            padding = 'max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        \n",
    "        labels = self.labels[index] \n",
    "        labels += [self.pad_idx]*(self.max_len-len(labels))      # pad to the right\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distributed-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-champion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "training_set = Encode(train_words, enumerated_train_tags, tags_vocab, tokenizer, MAX_LEN, PAD_IDX)\n",
    "validating_set = Encode(valid_words, enumerated_valid_tags, tags_vocab, tokenizer, MAX_LEN, PAD_IDX)\n",
    "testing_set = Encode(test_words, enumerated_test_tags, tags_vocab, tokenizer, MAX_LEN, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addressed-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validating_loader = DataLoader(validating_set, **valid_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-mayor",
   "metadata": {},
   "source": [
    "# 4. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amino-values",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/VinAIResearch/PhoBERT\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ordinary-lafayette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "focused-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/bentrevett/pytorch-pos-tagging/blob/master/2_transformer.ipynb\n",
    "class PhoBERTPoSTagger(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 output_dim, \n",
    "                 dropout):\n",
    "        \n",
    "        super(PhoBERTPoSTagger, self).__init__()\n",
    "        self.bert = bert\n",
    "        for params in self.bert.parameters():\n",
    "            params.requires_grad =  True\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.fc1 = nn.Linear(embedding_dim, 512)\n",
    "        self.fc2 = nn.Linear(512,256 )\n",
    "        self.fc = nn.Linear(256, output_dim)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, ids):\n",
    "  \n",
    "        # ids = (batch_size, max_len)\n",
    "    \n",
    "        outputs = self.bert(\n",
    "            input_ids=ids,\n",
    "        )\n",
    "        \n",
    "        # outputs = BERT return\n",
    "    \n",
    "        outputs = outputs[0]\n",
    "        \n",
    "        # outputs = (batch_size, max_len, hidden_size)\n",
    "        \n",
    "        outputs = F.relu(self.fc1(self.dropout1(outputs)))\n",
    "        outputs =  F.relu(self.fc2(self.dropout2(outputs)))\n",
    "        outputs =  self.fc(self.dropout(outputs))\n",
    "        \n",
    "        # outputs = (batch_size, max_len, output_dim)\n",
    "        \n",
    "        outputs = outputs.permute(1,0,2)\n",
    "        \n",
    "        # outputs = (max_len, batch_size, output_dim)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unexpected-waters",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dim = len(tags_vocab)+1\n",
    "dropout = 0.25\n",
    "\n",
    "model = PhoBERTPoSTagger(phobert,\n",
    "                      output_dim, \n",
    "                      dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-processing",
   "metadata": {},
   "source": [
    "# 5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "composite-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "driven-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "second-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, labels, pad_idx):\n",
    "    max_pred_idx = preds.argmax(dim=1, keepdim = True)\n",
    "    tags_idx = (labels != pad_idx).nonzero()\n",
    "    correct = max_pred_idx[tags_idx].squeeze(1).eq(labels[tags_idx])\n",
    "    return correct.sum() / torch.FloatTensor([labels[tags_idx].shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "attractive-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_loader, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    for _,batch in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        #model.zero_grad()\n",
    "        \n",
    "                \n",
    "        input_ids = batch['ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "                \n",
    "        outputs = model(input_ids)\n",
    "                \n",
    "        # outputs = (max_len, batch_size, output_dim)\n",
    "        # labels = (batch_size, max_len)\n",
    "                \n",
    "        labels = labels.permute(1,0)\n",
    "        # labels = (max_len, batch_size)\n",
    "                \n",
    "        outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
    "                \n",
    "        labels = labels.contiguous().view(-1)\n",
    "                \n",
    "        # outputs = (max_len*batch_size, output_dim)\n",
    "        # labels = (max_len*batch_size)\n",
    "                \n",
    "        # Note: Seperating words into sentences is not necessary anymore, \n",
    "        #       we only care if an output word matches its label\n",
    "                                \n",
    "        loss = criterion(outputs, labels)\n",
    "        acc = compute_accuracy(outputs, labels, tag_pad_idx)\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(training_loader), epoch_acc / len(training_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9860fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, validating_loader, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _,batch in enumerate(validating_loader):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids)\n",
    "\n",
    "            # outputs = (max_len, batch_size, output_dim)\n",
    "            # labels = (batch_size, max_len)\n",
    "\n",
    "            labels = labels.permute(1,0)\n",
    "            # labels = (max_len, batch_size)\n",
    "\n",
    "            outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
    "\n",
    "            labels = labels.contiguous().view(-1)\n",
    "\n",
    "            # outputs = (max_len*batch_size, output_dim)\n",
    "            # labels = (max_len*batch_size)\n",
    "\n",
    "            # Note: Seperating words into sentences is not necessary anymore, \n",
    "            #       we only care if an output word matches its label\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = compute_accuracy(outputs, labels, 0)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(validating_loader), epoch_acc / len(validating_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "written-hawaiian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "N_EPOCHS = 40\n",
    "LEARNING_RATE = 1e-05\n",
    "optimizer = optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6695201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    best_valid_loss = float('inf')\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch+1, N_EPOCHS))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model, training_loader, optimizer, criterion, PAD_IDX)\n",
    "        valid_loss, valid_acc = evaluate(model, validating_loader, criterion, PAD_IDX)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'postag-model.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6960bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.205 | Test Acc: 94.90%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('postag-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, testing_loader, criterion, PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9b27d",
   "metadata": {},
   "source": [
    "# NER it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28d1ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_3(file_name):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name - string\n",
    "        a path to a file with an annotated corpus\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    words - a list of lists of words\n",
    "    tags - a list of lists of tags\n",
    "        For example, the first sentence in a file is word1-tag1, word2-tag2 \n",
    "        and the next sentence is word3_/_tag3. Then you should get:\n",
    "        words = [['word1','word2'],['word3']]\n",
    "        tags = [['tag1','tag2'],['tag3']]\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_name) as f:\n",
    "        txt = f.read().split('\\n')\n",
    "    words = []\n",
    "    tags = []\n",
    "    sentence_words = []\n",
    "    sentence_tags = []\n",
    "    for row in txt:\n",
    "        # row: word, pos, chunking, ner\n",
    "        if not row:\n",
    "            words.append(sentence_words)\n",
    "            tags.append(sentence_tags)\n",
    "            sentence_words = []\n",
    "            sentence_tags = []\n",
    "            \n",
    "        if row:\n",
    "            word, _, _, ner, _ = row.split('\\t')\n",
    "            if word:\n",
    "                sentence_words.append(word)\n",
    "                sentence_tags.append(ner)\n",
    "    \n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ca12d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14027\n",
      "2831\n",
      "2831\n"
     ]
    }
   ],
   "source": [
    "ners_vocab_path = cwd+'/data/ner/ners_vocab.txt'\n",
    "train_path = cwd+'/data/ner/train.txt'\n",
    "valid_path = cwd+'/data/ner/dev.txt'\n",
    "test_path = cwd+'/data/ner/test.txt'\n",
    "\n",
    "ners_vocab, ners_vocab_dict = read_1(ners_vocab_path)\n",
    "train_words, train_tags = read_3(train_path)\n",
    "valid_words, valid_tags = read_3(valid_path)\n",
    "test_words, test_tags = read_3(test_path)\n",
    "\n",
    "print(len(train_words))\n",
    "print(len(valid_words))\n",
    "print(len(test_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da09ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag2num(tags_vocab):\n",
    "    return dict(zip( tags_vocab, range(1, len(tags_vocab)+1) ))\n",
    "\n",
    "tag2num = tag2num(ners_vocab)\n",
    "num2tag = {v: k for k, v in tag2num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaf70b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enumerate_tags(sentence_tags, tag2num):\n",
    "    converted_tags = [ list(map(lambda x: tag2num[x], sentence_tag)) for sentence_tag in sentence_tags ]\n",
    "    return converted_tags\n",
    "\n",
    "enumerated_train_tags = Enumerate_tags(train_tags, tag2num)\n",
    "enumerated_valid_tags = Enumerate_tags(valid_tags, tag2num)\n",
    "enumerated_test_tags = Enumerate_tags(test_tags, tag2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa82fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 20\n",
    "VALID_BATCH_SIZE = 20\n",
    "TEST_BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9232c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Encode(train_words, enumerated_train_tags, ners_vocab, tokenizer, MAX_LEN, PAD_IDX)\n",
    "validating_set = Encode(valid_words, enumerated_valid_tags, ners_vocab, tokenizer, MAX_LEN, PAD_IDX)\n",
    "testing_set = Encode(test_words, enumerated_test_tags, ners_vocab, tokenizer, MAX_LEN, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27828b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validating_loader = DataLoader(validating_set, **valid_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbafc5b",
   "metadata": {},
   "source": [
    "Precision is the percentage of named entities found by the learning system that are correct. Recall is the percentage of named entities present in the corpus that are found by the system. A named entity is correct only if it is an exact match of the corresponding entity in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad9f44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4f3e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(preds, labels, pad_idx):\n",
    "    # Get predicted label by taking the one with largest prob\n",
    "    max_pred_idx = np.argmax(preds, axis=2)\n",
    "    tags_idx = np.argwhere(labels != 0)\n",
    "    y_true_tags = []\n",
    "    y_pred_tags = []\n",
    "    for i_sentence in range(len(labels)):\n",
    "        label = labels[i_sentence]\n",
    "        pred = max_pred_idx[i_sentence]\n",
    "        tags_idx = (label != pad_idx).nonzero()\n",
    "        label = label[tags_idx].flatten()\n",
    "        \n",
    "        pred = pred[tags_idx].flatten()\n",
    "        \n",
    "\n",
    "        tags_idx = (pred != pad_idx).nonzero()\n",
    "        y_true_num = label[tags_idx].flatten()\n",
    "        y_pred_num = pred[tags_idx].flatten()\n",
    "        y_true_tag = [num2tag[num] for num in y_true_num]\n",
    "        y_pred_tag = [num2tag[num] for num in y_pred_num]\n",
    "        y_true_tags.append(y_true_tag)\n",
    "        y_pred_tags.append(y_pred_tag)\n",
    "    \n",
    "    return f1_score(y_true_tags, y_pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "806bc0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.array([[[0.4,0.5,0.8], [0.9,0.2,0.3]],[[0.5,0.3,0.2],[0.1,0.8,0.1]]])\n",
    "labels = np.array([[1,0],[1,2]])\n",
    "compute_f1(preds, labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57ced27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([2, 0])[torch.tensor([[0]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cfebe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(ners_vocab)+1\n",
    "dropout = 0.25\n",
    "\n",
    "model = PhoBERTPoSTagger(phobert,\n",
    "                      output_dim, \n",
    "                      dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11403593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_loader, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1 = 0\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    for _,batch in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        #model.zero_grad()\n",
    "        \n",
    "                \n",
    "        input_ids = batch['ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "                \n",
    "        outputs = model(input_ids)\n",
    "        \n",
    "                \n",
    "        # outputs = (max_len, batch_size, output_dim)\n",
    "        # labels = (batch_size, max_len)\n",
    "                \n",
    "        labels = labels.permute(1,0)\n",
    "        # labels = (max_len, batch_size)\n",
    "        f1 = compute_f1(outputs.detach().cpu().numpy(), labels.detach().cpu().numpy(), 0)\n",
    "                \n",
    "        outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
    "                \n",
    "        labels = labels.contiguous().view(-1)\n",
    "                \n",
    "        # outputs = (max_len*batch_size, output_dim)\n",
    "        # labels = (max_len*batch_size)\n",
    "                \n",
    "        # Note: Seperating words into sentences is not necessary anymore, \n",
    "        #       we only care if an output word matches its label\n",
    "                                \n",
    "        loss = criterion(outputs, labels)\n",
    "        acc = compute_accuracy(outputs, labels, tag_pad_idx)\n",
    "        \n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(training_loader), epoch_acc / len(training_loader), epoch_f1 / len(training_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de92e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, validating_loader, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1 = 0\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _,batch in enumerate(validating_loader):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids)\n",
    "\n",
    "            # outputs = (max_len, batch_size, output_dim)\n",
    "            # labels = (batch_size, max_len)\n",
    "\n",
    "            labels = labels.permute(1,0)\n",
    "            # labels = (max_len, batch_size)\n",
    "            f1 = compute_f1(outputs.detach().cpu().numpy(), labels.detach().cpu().numpy(), 0)\n",
    "\n",
    "            outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
    "\n",
    "            labels = labels.contiguous().view(-1)\n",
    "\n",
    "            # outputs = (max_len*batch_size, output_dim)\n",
    "            # labels = (max_len*batch_size)\n",
    "\n",
    "            # Note: Seperating words into sentences is not necessary anymore, \n",
    "            #       we only care if an output word matches its label\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = compute_accuracy(outputs, labels, 0)\n",
    "            \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(training_loader), epoch_acc / len(training_loader), epoch_f1 / len(training_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d4e01bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67fed8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "N_EPOCHS = 40\n",
    "LEARNING_RATE = 1e-05\n",
    "optimizer = optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "408eb848",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 40 ========\n",
      "Epoch: 01 | Epoch Time: 8m 44s\n",
      "\tTrain Loss: 0.453 | Train Acc: 93.28% | Train F1: 0.155\n",
      "\t Val. Loss: 0.031 |  Val. Acc: 19.23% | Val. F1: 0.088\n",
      "\n",
      "======== Epoch 2 / 40 ========\n",
      "Epoch: 02 | Epoch Time: 8m 45s\n",
      "\tTrain Loss: 0.128 | Train Acc: 96.06% | Train F1: 0.650\n",
      "\t Val. Loss: 0.018 |  Val. Acc: 19.57% | Val. F1: 0.161\n",
      "\n",
      "======== Epoch 3 / 40 ========\n",
      "Epoch: 03 | Epoch Time: 8m 45s\n",
      "\tTrain Loss: 0.065 | Train Acc: 98.18% | Train F1: 0.865\n",
      "\t Val. Loss: 0.010 |  Val. Acc: 19.95% | Val. F1: 0.178\n",
      "\n",
      "======== Epoch 4 / 40 ========\n",
      "Epoch: 04 | Epoch Time: 8m 45s\n",
      "\tTrain Loss: 0.039 | Train Acc: 98.98% | Train F1: 0.909\n",
      "\t Val. Loss: 0.007 |  Val. Acc: 20.05% | Val. F1: 0.184\n",
      "\n",
      "======== Epoch 5 / 40 ========\n",
      "Epoch: 05 | Epoch Time: 8m 45s\n",
      "\tTrain Loss: 0.028 | Train Acc: 99.27% | Train F1: 0.933\n",
      "\t Val. Loss: 0.006 |  Val. Acc: 20.07% | Val. F1: 0.190\n",
      "\n",
      "======== Epoch 6 / 40 ========\n",
      "Epoch: 06 | Epoch Time: 8m 45s\n",
      "\tTrain Loss: 0.021 | Train Acc: 99.48% | Train F1: 0.954\n",
      "\t Val. Loss: 0.005 |  Val. Acc: 20.10% | Val. F1: 0.192\n",
      "\n",
      "======== Epoch 7 / 40 ========\n",
      "Epoch: 07 | Epoch Time: 8m 45s\n",
      "\tTrain Loss: 0.016 | Train Acc: 99.61% | Train F1: 0.968\n",
      "\t Val. Loss: 0.006 |  Val. Acc: 20.09% | Val. F1: 0.191\n",
      "\n",
      "======== Epoch 8 / 40 ========\n",
      "Epoch: 08 | Epoch Time: 8m 45s\n",
      "\tTrain Loss: 0.012 | Train Acc: 99.69% | Train F1: 0.976\n",
      "\t Val. Loss: 0.006 |  Val. Acc: 20.09% | Val. F1: 0.190\n",
      "\n",
      "======== Epoch 9 / 40 ========\n",
      "Epoch: 09 | Epoch Time: 8m 45s\n",
      "\tTrain Loss: 0.011 | Train Acc: 99.74% | Train F1: 0.976\n",
      "\t Val. Loss: 0.006 |  Val. Acc: 20.09% | Val. F1: 0.191\n",
      "\n",
      "======== Epoch 10 / 40 ========\n",
      "Epoch: 10 | Epoch Time: 8m 46s\n",
      "\tTrain Loss: 0.008 | Train Acc: 99.81% | Train F1: 0.983\n",
      "\t Val. Loss: 0.006 |  Val. Acc: 20.10% | Val. F1: 0.191\n",
      "\n",
      "======== Epoch 11 / 40 ========\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19147/2119857645.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPAD_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidating_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPAD_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19147/374853527.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, training_loader, optimizer, criterion, tag_pad_idx)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_19147/990900370.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# ids = (batch_size, max_len)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         )\n\u001b[0;32m--> 848\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 )\n\u001b[1;32m    521\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    523\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         )\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    best_valid_f1 = -float('inf')\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch+1, N_EPOCHS))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc, train_f1 = train(model, training_loader, optimizer, criterion, PAD_IDX)\n",
    "        valid_loss, valid_acc, valid_f1 = evaluate(model, validating_loader, criterion, PAD_IDX)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_f1 > best_valid_f1:\n",
    "            best_valid_f1 = valid_f1\n",
    "            torch.save(model.state_dict(), 'ner-model.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1: {train_f1:.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1: {valid_f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f45044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('ner-model.pt'))\n",
    "\n",
    "test_loss, test_acc, test_f1 = evaluate(model, testing_loader, criterion, PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1: {test_f1:.3f}'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83069d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
