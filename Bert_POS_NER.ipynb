{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "introductory-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True to skip training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "black-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, AutoModel, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "import functools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d06f24",
   "metadata": {},
   "source": [
    "Material:  \n",
    "https://www.vinai.io/phobert-the-first-public-large-scale-language-models-for-vietnamese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-wrist",
   "metadata": {},
   "source": [
    "# 1. Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-commission",
   "metadata": {},
   "source": [
    "https://github.com/datquocnguyen/VnDT#data-split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-berry",
   "metadata": {},
   "source": [
    "https://github.com/datquocnguyen/VnDT/blob/master/VnDT-paper-CameraReadyVersion.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-manner",
   "metadata": {},
   "source": [
    "## 1.1 Read the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "temporal-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_1(file_name):\n",
    "    with open(file_name, encoding='utf8') as f:\n",
    "        # line = ['Np Proper noun','Nc Classifier noun',...]\n",
    "        lines = re.split('\\n',f.read())\n",
    "    \n",
    "    tags = []\n",
    "    tag_dict = {}\n",
    "    for line in lines:\n",
    "        tmp = line.split(' ',1)\n",
    "        tags.append(tmp[0])\n",
    "        tag_dict[tmp[0]] = tmp[1]\n",
    "        \n",
    "    return tags, tag_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-sugar",
   "metadata": {},
   "source": [
    "## 1.2 Read train - dev - test corpuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "violent-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_2(file_name):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name - string\n",
    "        a path to a file with an annotated corpus\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    words - a list of lists of words\n",
    "    tags - a list of lists of tags\n",
    "        For example, the first sentence in a file is word1-tag1, word2-tag2 \n",
    "        and the next sentence is word3_/_tag3. Then you should get:\n",
    "        words = [['word1','word2'],['word3']]\n",
    "        tags = [['tag1','tag2'],['tag3']]\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_name, sep='\\t|\\n', names = ['idx','word','c3','c4','tag','c6','c7','c8','c9','c10'])\n",
    "    \n",
    "    words = []\n",
    "    tags = []\n",
    "    sentence_words = []\n",
    "    sentence_tags = []\n",
    "    prev_idx = 0\n",
    "    for _,row in df.iterrows():\n",
    "        if row['idx'] != prev_idx+1:\n",
    "            words.append(sentence_words)\n",
    "            tags.append(sentence_tags)\n",
    "            sentence_words = []\n",
    "            sentence_tags = []\n",
    "            \n",
    "        sentence_words.append(row['word'])\n",
    "        sentence_tags.append(row['tag'])\n",
    "        prev_idx = row['idx']\n",
    "            \n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-haiti",
   "metadata": {},
   "source": [
    "## 1.3 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fa0f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/m/home/home1/12/dangp1/unix/POS_NER'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "streaming-credits",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/12/dangp1/unix/.conda/envs/concac/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8976\n",
      "199\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "tags_vocab_path = cwd+'/data/tags_vocab.txt'\n",
    "train_path = cwd+'/data/train.txt'\n",
    "valid_path = cwd+'/data/dev.txt'\n",
    "test_path = cwd+'/data/test.txt'\n",
    "\n",
    "tags_vocab, tags_vocab_dict = read_1(tags_vocab_path)\n",
    "train_words, train_tags = read_2(train_path)\n",
    "valid_words, valid_tags = read_2(valid_path)\n",
    "test_words, test_tags = read_2(test_path)\n",
    "\n",
    "print(len(train_words))\n",
    "print(len(valid_words))\n",
    "print(len(test_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-recycling",
   "metadata": {},
   "source": [
    "## 1.4 Enumerate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "municipal-jaguar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tag2num(tags_vocab):\n",
    "    return dict(zip( tags_vocab, range(1, len(tags_vocab)+1) ))\n",
    "\n",
    "tag2num = tag2num(tags_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "median-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enumerate_tags(sentence_tags, tag2num):\n",
    "    converted_tags = [ list(map(lambda x: tag2num[x], sentence_tag)) for sentence_tag in sentence_tags ]\n",
    "    return converted_tags\n",
    "\n",
    "enumerated_train_tags = Enumerate_tags(train_tags, tag2num)\n",
    "enumerated_valid_tags = Enumerate_tags(valid_tags, tag2num)\n",
    "enumerated_test_tags = Enumerate_tags(test_tags, tag2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "african-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-capacity",
   "metadata": {},
   "source": [
    "# 2. Study the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-recruitment",
   "metadata": {},
   "source": [
    "# 3. Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ahead-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encode(Dataset):\n",
    "    def __init__(self, words, tags, tags_vocab, tokenizer, max_len, pad_idx):\n",
    "        self.data = words\n",
    "        self.labels = tags\n",
    "        self.tags_vocab = tags_vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        self.len = len(self.data)\n",
    "        self.max_len = max_len\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.data[index],\n",
    "            None,\n",
    "            add_special_tokens=False,\n",
    "            max_length=self.max_len,\n",
    "            padding = 'max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        ids = inputs['input_ids']\n",
    "        \n",
    "        labels = self.labels[index] \n",
    "        labels += [self.pad_idx]*(self.max_len-len(labels))      # pad to the right\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(self.labels[index], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distributed-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-champion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "training_set = Encode(train_words, enumerated_train_tags, tags_vocab, tokenizer, MAX_LEN, PAD_IDX)\n",
    "validating_set = Encode(valid_words, enumerated_valid_tags, tags_vocab, tokenizer, MAX_LEN, PAD_IDX)\n",
    "testing_set = Encode(test_words, enumerated_test_tags, tags_vocab, tokenizer, MAX_LEN, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addressed-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validating_loader = DataLoader(validating_set, **valid_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-mayor",
   "metadata": {},
   "source": [
    "# 4. Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amino-values",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/VinAIResearch/PhoBERT\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ordinary-lafayette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "focused-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/bentrevett/pytorch-pos-tagging/blob/master/2_transformer.ipynb\n",
    "class PhoBERTPoSTagger(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 output_dim, \n",
    "                 dropout):\n",
    "        \n",
    "        super(PhoBERTPoSTagger, self).__init__()\n",
    "        self.bert = bert\n",
    "        for params in self.bert.parameters():\n",
    "            params.requires_grad =  True\n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.fc1 = nn.Linear(embedding_dim, 512)\n",
    "        self.fc2 = nn.Linear(512,256 )\n",
    "        self.fc = nn.Linear(256, output_dim)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, ids):\n",
    "  \n",
    "        # ids = (batch_size, max_len)\n",
    "    \n",
    "        outputs = self.bert(\n",
    "            input_ids=ids,\n",
    "        )\n",
    "        \n",
    "        # outputs = BERT return\n",
    "    \n",
    "        outputs = outputs[0]\n",
    "        \n",
    "        # outputs = (batch_size, max_len, hidden_size)\n",
    "        \n",
    "        outputs = F.relu(self.fc1(self.dropout1(outputs)))\n",
    "        outputs =  F.relu(self.fc2(self.dropout2(outputs)))\n",
    "        outputs =  self.fc(self.dropout(outputs))\n",
    "        \n",
    "        # outputs = (batch_size, max_len, output_dim)\n",
    "        \n",
    "        outputs = outputs.permute(1,0,2)\n",
    "        \n",
    "        # outputs = (max_len, batch_size, output_dim)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "unexpected-waters",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dim = len(tags_vocab)+1\n",
    "dropout = 0.25\n",
    "\n",
    "model = PhoBERTPoSTagger(phobert,\n",
    "                      output_dim, \n",
    "                      dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-processing",
   "metadata": {},
   "source": [
    "# 5. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "composite-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "driven-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "second-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, labels, pad_idx):\n",
    "    max_pred_idx = preds.argmax(dim=1, keepdim = True)\n",
    "    tags_idx = (labels != pad_idx).nonzero()\n",
    "    correct = max_pred_idx[tags_idx].squeeze(1).eq(labels[tags_idx])\n",
    "    return correct.sum() / torch.FloatTensor([labels[tags_idx].shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "attractive-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_loader, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    for _,batch in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        #model.zero_grad()\n",
    "        \n",
    "                \n",
    "        input_ids = batch['ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "                \n",
    "        outputs = model(input_ids)\n",
    "                \n",
    "        # outputs = (max_len, batch_size, output_dim)\n",
    "        # labels = (batch_size, max_len)\n",
    "                \n",
    "        labels = labels.permute(1,0)\n",
    "        # labels = (max_len, batch_size)\n",
    "                \n",
    "        outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
    "                \n",
    "        labels = labels.contiguous().view(-1)\n",
    "                \n",
    "        # outputs = (max_len*batch_size, output_dim)\n",
    "        # labels = (max_len*batch_size)\n",
    "                \n",
    "        # Note: Seperating words into sentences is not necessary anymore, \n",
    "        #       we only care if an output word matches its label\n",
    "                                \n",
    "        loss = criterion(outputs, labels)\n",
    "        acc = compute_accuracy(outputs, labels, tag_pad_idx)\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(training_loader), epoch_acc / len(training_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9860fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, validating_loader, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _,batch in enumerate(validating_loader):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids)\n",
    "\n",
    "            # outputs = (max_len, batch_size, output_dim)\n",
    "            # labels = (batch_size, max_len)\n",
    "\n",
    "            labels = labels.permute(1,0)\n",
    "            # labels = (max_len, batch_size)\n",
    "\n",
    "            outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
    "\n",
    "            labels = labels.contiguous().view(-1)\n",
    "\n",
    "            # outputs = (max_len*batch_size, output_dim)\n",
    "            # labels = (max_len*batch_size)\n",
    "\n",
    "            # Note: Seperating words into sentences is not necessary anymore, \n",
    "            #       we only care if an output word matches its label\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = compute_accuracy(outputs, labels, 0)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(validating_loader), epoch_acc / len(validating_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "written-hawaiian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "N_EPOCHS = 40\n",
    "LEARNING_RATE = 1e-05\n",
    "optimizer = optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6695201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    best_valid_loss = float('inf')\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch+1, N_EPOCHS))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model, training_loader, optimizer, criterion, PAD_IDX)\n",
    "        valid_loss, valid_acc = evaluate(model, validating_loader, criterion, PAD_IDX)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'postag-model.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6960bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.206 | Test Acc: 94.86%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('postag-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, testing_loader, criterion, PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9b27d",
   "metadata": {},
   "source": [
    "# NER it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28d1ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_3(file_name):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_name - string\n",
    "        a path to a file with an annotated corpus\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    words - a list of lists of words\n",
    "    tags - a list of lists of tags\n",
    "        For example, the first sentence in a file is word1-tag1, word2-tag2 \n",
    "        and the next sentence is word3_/_tag3. Then you should get:\n",
    "        words = [['word1','word2'],['word3']]\n",
    "        tags = [['tag1','tag2'],['tag3']]\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_name) as f:\n",
    "        txt = f.read().split('\\n')\n",
    "    words = []\n",
    "    tags = []\n",
    "    sentence_words = []\n",
    "    sentence_tags = []\n",
    "    for row in txt:\n",
    "        # row: word, pos, chunking, ner\n",
    "        if not row:\n",
    "            words.append(sentence_words)\n",
    "            tags.append(sentence_tags)\n",
    "            sentence_words = []\n",
    "            sentence_tags = []\n",
    "            \n",
    "        if row:\n",
    "            word, _, _, ner, _ = row.split('\\t')\n",
    "            if word:\n",
    "                sentence_words.append(word)\n",
    "                sentence_tags.append(ner)\n",
    "    \n",
    "    return words, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ca12d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14027\n",
      "2831\n",
      "2831\n"
     ]
    }
   ],
   "source": [
    "ners_vocab_path = cwd+'/data/ner/ners_vocab.txt'\n",
    "train_path = cwd+'/data/ner/train.txt'\n",
    "valid_path = cwd+'/data/ner/dev.txt'\n",
    "test_path = cwd+'/data/ner/test.txt'\n",
    "\n",
    "ners_vocab, ners_vocab_dict = read_1(ners_vocab_path)\n",
    "train_words, train_tags = read_3(train_path)\n",
    "valid_words, valid_tags = read_3(valid_path)\n",
    "test_words, test_tags = read_3(test_path)\n",
    "\n",
    "print(len(train_words))\n",
    "print(len(valid_words))\n",
    "print(len(test_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da09ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag2num(tags_vocab):\n",
    "    return dict(zip( tags_vocab, range(1, len(tags_vocab)+1) ))\n",
    "\n",
    "tag2num = tag2num(ners_vocab)\n",
    "num2tag = {v: k for k, v in tag2num.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaf70b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enumerate_tags(sentence_tags, tag2num):\n",
    "    converted_tags = [ list(map(lambda x: tag2num[x], sentence_tag)) for sentence_tag in sentence_tags ]\n",
    "    return converted_tags\n",
    "\n",
    "enumerated_train_tags = Enumerate_tags(train_tags, tag2num)\n",
    "enumerated_valid_tags = Enumerate_tags(valid_tags, tag2num)\n",
    "enumerated_test_tags = Enumerate_tags(test_tags, tag2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa82fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9232c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Encode(train_words, enumerated_train_tags, ners_vocab, tokenizer, MAX_LEN, PAD_IDX)\n",
    "validating_set = Encode(valid_words, enumerated_valid_tags, ners_vocab, tokenizer, MAX_LEN, PAD_IDX)\n",
    "testing_set = Encode(test_words, enumerated_test_tags, ners_vocab, tokenizer, MAX_LEN, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27828b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validating_loader = DataLoader(validating_set, **valid_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbafc5b",
   "metadata": {},
   "source": [
    "Precision is the percentage of named entities found by the learning system that are correct. Recall is the percentage of named entities present in the corpus that are found by the system. A named entity is correct only if it is an exact match of the corresponding entity in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad9f44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4f3e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(preds, labels, pad_idx):\n",
    "    # Get predicted label by taking the one with largest prob\n",
    "    max_pred_idx = preds.argmax(dim=2)\n",
    "    # Get indices of labels that is not pad_idx\n",
    "    tags_idx = (labels != pad_idx).nonzero()\n",
    "    \n",
    "    y_true_tags = []\n",
    "    y_pred_tags = []\n",
    "    for i_sentence in range(len(labels)):\n",
    "        label = labels[i_sentence]\n",
    "        pred = max_pred_idx[i_sentence]\n",
    "        tags_idx = (label != pad_idx).nonzero()\n",
    "        print(pred)\n",
    "        label = label[tags_idx].flatten()\n",
    "        pred = pred[tags_idx].flatten()\n",
    "        print(pred)\n",
    "        \n",
    "        tags_idx = (pred != pad_idx).nonzero()\n",
    "        y_true_num = label[tags_idx].flatten().detach().cpu().tolist()\n",
    "        y_pred_num = pred[tags_idx].flatten().detach().cpu().tolist()\n",
    "        print('label:', y_true_num)\n",
    "        print('pred:', y_pred_num)\n",
    "        y_true_tag = [num2tag[num] for num in y_true_num]\n",
    "        y_pred_tag = [num2tag[num] for num in y_pred_num]\n",
    "        y_true_tags.append(y_true_tag)\n",
    "        y_pred_tags.append(y_pred_tag)\n",
    "    \n",
    "    #print(y_true_tags)\n",
    "    #print(y_pred_tags)\n",
    "    \n",
    "    return f1_score(y_true_tags, y_pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "806bc0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0])\n",
      "tensor([2, 0])\n",
      "label: [1]\n",
      "pred: [2]\n",
      "tensor([0, 1])\n",
      "tensor([0, 1])\n",
      "label: [2]\n",
      "pred: [1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.tensor([[[0.4,0.5,0.8], [0.9,0.2,0.3]],[[0.5,0.3,0.2],[0.1,0.8,0.1]]])\n",
    "labels = torch.tensor([[1,2],[1,2]])\n",
    "compute_f1(preds, labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cfebe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(ners_vocab)+1\n",
    "dropout = 0.25\n",
    "\n",
    "model = PhoBERTPoSTagger(phobert,\n",
    "                      output_dim, \n",
    "                      dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11403593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, training_loader, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1 = 0\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    for _,batch in enumerate(training_loader):\n",
    "        optimizer.zero_grad()\n",
    "        #model.zero_grad()\n",
    "        \n",
    "                \n",
    "        input_ids = batch['ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "                \n",
    "        outputs = model(input_ids)\n",
    "        f1 = compute_f1(outputs, labels, 0)\n",
    "                \n",
    "        # outputs = (max_len, batch_size, output_dim)\n",
    "        # labels = (batch_size, max_len)\n",
    "                \n",
    "        labels = labels.permute(1,0)\n",
    "        # labels = (max_len, batch_size)\n",
    "                \n",
    "        outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
    "                \n",
    "        labels = labels.contiguous().view(-1)\n",
    "                \n",
    "        # outputs = (max_len*batch_size, output_dim)\n",
    "        # labels = (max_len*batch_size)\n",
    "                \n",
    "        # Note: Seperating words into sentences is not necessary anymore, \n",
    "        #       we only care if an output word matches its label\n",
    "                                \n",
    "        loss = criterion(outputs, labels)\n",
    "        acc = compute_accuracy(outputs, labels, tag_pad_idx)\n",
    "        \n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(training_loader), epoch_acc / len(training_loader), epoch_f1 / len(training_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de92e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, validating_loader, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _,batch in enumerate(validating_loader):\n",
    "            input_ids = batch['ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids)\n",
    "            f1 = compute_f1(outputs.copy(), labels.copy(), 0)\n",
    "\n",
    "            # outputs = (max_len, batch_size, output_dim)\n",
    "            # labels = (batch_size, max_len)\n",
    "\n",
    "            labels = labels.permute(1,0)\n",
    "            # labels = (max_len, batch_size)\n",
    "\n",
    "            outputs = outputs.contiguous().view(-1, outputs.shape[-1])\n",
    "\n",
    "            labels = labels.contiguous().view(-1)\n",
    "\n",
    "            # outputs = (max_len*batch_size, output_dim)\n",
    "            # labels = (max_len*batch_size)\n",
    "\n",
    "            # Note: Seperating words into sentences is not necessary anymore, \n",
    "            #       we only care if an output word matches its label\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            acc = compute_accuracy(outputs, labels, 0)\n",
    "            \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(training_loader), epoch_acc / len(training_loader), epoch_f1 / len(training_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4e01bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67fed8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss(ignore_index = PAD_IDX)\n",
    "N_EPOCHS = 40\n",
    "LEARNING_RATE = 1e-05\n",
    "optimizer = optim.AdamW(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "408eb848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 40 ========\n",
      "tensor([3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 4, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 0, 3, 3, 1, 3], device='cuda:0')\n",
      "tensor([3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 4, 3, 3, 3, 1, 3, 3, 3, 3, 3],\n",
      "       device='cuda:0')\n",
      "label: [9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "pred: [3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 3, 3, 4, 3, 3, 3, 1, 3, 3, 3, 3, 3]\n",
      "tensor([1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3,\n",
      "        5, 3, 1, 1, 3, 3, 1, 3], device='cuda:0')\n",
      "tensor([1, 3, 3, 3], device='cuda:0')\n",
      "label: [9, 9, 9, 9]\n",
      "pred: [1, 3, 3, 3]\n",
      "tensor([3, 3, 1, 3, 3, 4, 3, 1, 3, 0, 3, 3, 1, 3, 5, 3, 3, 3, 3, 8, 8, 1, 3, 3,\n",
      "        7, 3, 4, 3, 3, 7, 3, 3], device='cuda:0')\n",
      "tensor([3, 3, 1, 3, 3, 4, 3, 1, 3, 0, 3, 3, 1, 3, 5, 3, 3, 3, 3],\n",
      "       device='cuda:0')\n",
      "label: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9]\n",
      "pred: [3, 3, 1, 3, 3, 4, 3, 1, 3, 3, 3, 1, 3, 5, 3, 3, 3, 3]\n",
      "tensor([3, 3, 5, 3, 3, 4, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1,\n",
      "        3, 3, 3, 3, 3, 0, 3, 3], device='cuda:0')\n",
      "tensor([3, 3, 5, 3, 3, 4, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1,\n",
      "        3, 3, 3, 3], device='cuda:0')\n",
      "label: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "pred: [3, 3, 5, 3, 3, 4, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 3]\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1,\n",
      "        7, 3, 3, 3, 3, 3, 1, 3], device='cuda:0')\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3],\n",
      "       device='cuda:0')\n",
      "label: [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "pred: [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3]\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 1, 3, 3, 3, 5, 1, 3, 3,\n",
      "        0, 3, 1, 3, 3, 3, 3, 7], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [32,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [33,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [34,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [35,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [36,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [37,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [38,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [39,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [40,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [41,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [42,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [43,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [44,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [45,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [46,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [47,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [48,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [49,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [50,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [51,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [52,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [53,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [54,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4110207/2145915608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPAD_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidating_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPAD_IDX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4110207/1860887617.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, training_loader, optimizer, criterion, tag_pad_idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# outputs = (max_len, batch_size, output_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4110207/4023647540.py\u001b[0m in \u001b[0;36mcompute_f1\u001b[0;34m(preds, labels, pad_idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtags_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtags_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtags_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpad_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mvalue_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/concac/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    best_valid_f1 = -float('inf')\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch+1, N_EPOCHS))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc, train_f1 = train(model, training_loader, optimizer, criterion, PAD_IDX)\n",
    "        valid_loss, valid_acc, valid_f1 = evaluate(model, validating_loader, criterion, PAD_IDX)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_f1 > best_valid_f1:\n",
    "            best_valid_f1 = valid_f1\n",
    "            torch.save(model.state_dict(), 'ner-model.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Train F1: {train_f1:.3f}')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% | Val. F1: {eval_f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f45044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('ner-model.pt'))\n",
    "\n",
    "test_loss, test_acc, test_f1 = evaluate(model, testing_loader, criterion, PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Test F1: {test_f1:.3f}'')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
